{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fire Prediction**"
      ],
      "metadata": {
        "id": "BjypvgQffajT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Paths\n",
        "TRAIN_DIR = \"/content/drive/MyDrive/Data/Train_Data\"\n",
        "TEST_DIR  = \"/content/drive/MyDrive/Data/Test_Data\"\n",
        "\n",
        "# Image parameters\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5  # You can increase for better accuracy\n",
        "\n",
        "# 1️⃣ Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# 2️⃣ Model creation\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3️⃣ Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# 4️⃣ Save the model\n",
        "model.save(\"/content/drive/MyDrive/fire_detection_mobilenetv2.h5\")\n",
        "print(\"Model saved!\")\n",
        "\n",
        "# 5️⃣ Load the model\n",
        "model = load_model(\"/content/drive/MyDrive/fire_detection_mobilenetv2.h5\")\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "# 6️⃣ Test images\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=1,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\nTesting Images ---\")\n",
        "for i in range(len(test_generator.filenames)):\n",
        "    img_path = os.path.join(TEST_DIR, test_generator.filenames[i])\n",
        "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    score = model.predict(img_array, verbose=0)[0][0]\n",
        "    pred_label = \"Fire\" if score >= 0.5 else \"Non-Fire\"\n",
        "    true_label = \"Fire\" if \"Fire\" in test_generator.filenames[i] else \"Non-Fire\"\n",
        "\n",
        "    print(f\"{test_generator.filenames[i]:<25} | True: {true_label:<8} | Score: {score:.3f} | Pred: {pred_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqCyJXWcWX0r",
        "outputId": "ac4953bb-6650-4f20-a87b-a120674f3680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3689 images belonging to 2 classes.\n",
            "Found 922 images belonging to 2 classes.\n",
            "Class indices: {'Fire': 0, 'Non_Fire': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.8303 - loss: 0.3924 - val_accuracy: 0.9360 - val_loss: 0.1910\n",
            "Epoch 2/5\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 704ms/step - accuracy: 0.9572 - loss: 0.1245 - val_accuracy: 0.9458 - val_loss: 0.1515\n",
            "Epoch 3/5\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 695ms/step - accuracy: 0.9642 - loss: 0.1082 - val_accuracy: 0.9447 - val_loss: 0.1589\n",
            "Epoch 4/5\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 700ms/step - accuracy: 0.9664 - loss: 0.0861 - val_accuracy: 0.9512 - val_loss: 0.1218\n",
            "Epoch 5/5\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 713ms/step - accuracy: 0.9741 - loss: 0.0809 - val_accuracy: 0.9577 - val_loss: 0.1282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded!\n",
            "Found 50 images belonging to 2 classes.\n",
            "\n",
            "Testing Images ---\n",
            "Fire/F_0.jpg              | True: Fire     | Score: 0.035 | Pred: Non-Fire\n",
            "Fire/F_1.jpg              | True: Fire     | Score: 0.003 | Pred: Non-Fire\n",
            "Fire/F_10.jpg             | True: Fire     | Score: 0.006 | Pred: Non-Fire\n",
            "Fire/F_11.jpg             | True: Fire     | Score: 0.039 | Pred: Non-Fire\n",
            "Fire/F_12.jpg             | True: Fire     | Score: 0.001 | Pred: Non-Fire\n",
            "Fire/F_13.jpg             | True: Fire     | Score: 0.013 | Pred: Non-Fire\n",
            "Fire/F_14.jpg             | True: Fire     | Score: 0.198 | Pred: Non-Fire\n",
            "Fire/F_15.jpg             | True: Fire     | Score: 0.001 | Pred: Non-Fire\n",
            "Fire/F_16.jpg             | True: Fire     | Score: 0.003 | Pred: Non-Fire\n",
            "Fire/F_17.jpg             | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_18.jpg             | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_19.jpg             | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_2.jpg              | True: Fire     | Score: 0.079 | Pred: Non-Fire\n",
            "Fire/F_20.jpg             | True: Fire     | Score: 0.087 | Pred: Non-Fire\n",
            "Fire/F_21.jpg             | True: Fire     | Score: 0.007 | Pred: Non-Fire\n",
            "Fire/F_22.jpg             | True: Fire     | Score: 0.009 | Pred: Non-Fire\n",
            "Fire/F_23.jpg             | True: Fire     | Score: 0.046 | Pred: Non-Fire\n",
            "Fire/F_24.jpg             | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_3.jpg              | True: Fire     | Score: 0.020 | Pred: Non-Fire\n",
            "Fire/F_4.jpg              | True: Fire     | Score: 0.004 | Pred: Non-Fire\n",
            "Fire/F_5.jpg              | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_6.jpg              | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_7.jpg              | True: Fire     | Score: 0.027 | Pred: Non-Fire\n",
            "Fire/F_8.jpg              | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Fire/F_9.jpg              | True: Fire     | Score: 0.000 | Pred: Non-Fire\n",
            "Non_Fire/NF_0.jpg         | True: Fire     | Score: 0.104 | Pred: Non-Fire\n",
            "Non_Fire/NF_1.jpg         | True: Fire     | Score: 0.683 | Pred: Fire\n",
            "Non_Fire/NF_10.jpg        | True: Fire     | Score: 0.561 | Pred: Fire\n",
            "Non_Fire/NF_11.jpg        | True: Fire     | Score: 0.573 | Pred: Fire\n",
            "Non_Fire/NF_12.jpg        | True: Fire     | Score: 0.419 | Pred: Non-Fire\n",
            "Non_Fire/NF_13.jpg        | True: Fire     | Score: 0.993 | Pred: Fire\n",
            "Non_Fire/NF_14.jpg        | True: Fire     | Score: 0.997 | Pred: Fire\n",
            "Non_Fire/NF_15.jpg        | True: Fire     | Score: 0.899 | Pred: Fire\n",
            "Non_Fire/NF_16.jpg        | True: Fire     | Score: 0.852 | Pred: Fire\n",
            "Non_Fire/NF_17.jpg        | True: Fire     | Score: 0.510 | Pred: Fire\n",
            "Non_Fire/NF_18.jpg        | True: Fire     | Score: 0.984 | Pred: Fire\n",
            "Non_Fire/NF_19.jpg        | True: Fire     | Score: 0.255 | Pred: Non-Fire\n",
            "Non_Fire/NF_2.jpg         | True: Fire     | Score: 0.645 | Pred: Fire\n",
            "Non_Fire/NF_20.jpg        | True: Fire     | Score: 0.842 | Pred: Fire\n",
            "Non_Fire/NF_21.jpg        | True: Fire     | Score: 0.142 | Pred: Non-Fire\n",
            "Non_Fire/NF_22.jpg        | True: Fire     | Score: 0.381 | Pred: Non-Fire\n",
            "Non_Fire/NF_23.jpg        | True: Fire     | Score: 0.845 | Pred: Fire\n",
            "Non_Fire/NF_24.jpg        | True: Fire     | Score: 0.918 | Pred: Fire\n",
            "Non_Fire/NF_3.jpg         | True: Fire     | Score: 0.888 | Pred: Fire\n",
            "Non_Fire/NF_4.jpg         | True: Fire     | Score: 0.850 | Pred: Fire\n",
            "Non_Fire/NF_5.jpg         | True: Fire     | Score: 0.969 | Pred: Fire\n",
            "Non_Fire/NF_6.jpg         | True: Fire     | Score: 0.996 | Pred: Fire\n",
            "Non_Fire/NF_7.jpg         | True: Fire     | Score: 0.911 | Pred: Fire\n",
            "Non_Fire/NF_8.jpg         | True: Fire     | Score: 0.920 | Pred: Fire\n",
            "Non_Fire/NF_9.jpg         | True: Fire     | Score: 0.910 | Pred: Fire\n"
          ]
        }
      ]
    }
  ]
}